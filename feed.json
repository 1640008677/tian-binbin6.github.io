{
    "version": "https://jsonfeed.org/version/1",
    "title": "韓",
    "subtitle": "",
    "icon": "https://www.jackfruit.top/images/favicon.ico",
    "description": "欢迎来到❥憨憨的穗穗彬耶❥的个人博客",
    "home_page_url": "https://www.jackfruit.top",
    "items": [
        {
            "id": "https://www.jackfruit.top/2023/02/28/pageabout/",
            "url": "https://www.jackfruit.top/2023/02/28/pageabout/",
            "title": "pageabout",
            "date_published": "2023-02-27T16:02:49.000Z",
            "content_html": "<h3 id=\"第一次编写个人博客づ-̄3-̄づ️~\"><a class=\"anchor\" href=\"#第一次编写个人博客づ-̄3-̄づ️~\">#</a> 第一次编写个人博客（づ￣3￣）づ╭❤️～</h3>\n<h5 id=\"收获\"><a class=\"anchor\" href=\"#收获\">#</a> 收获😊：</h5>\n<pre><code>\t第一次编写博客是套用别人的方法使用的，外观、图片、CSS样式、渲染器等等等....\n</code></pre>\n<p>​\t<strong>收获到许多，了解到一个网站是如何建成的（虽然是最简单搭建，用时：5 个小时多一点～～～）。比如说如何建仓库，无后端评论区，搜索引擎等，，，这些都是委托在第三方平台上搭建起来的，代码没改太多（都是 copy 别人的样式，主题，，）。现在先模仿，后期再慢慢摸索。</strong></p>\n<p>这个网站我也会维护下去，但是至于是啥时候更新就不一定了。</p>\n",
            "tags": []
        },
        {
            "id": "https://www.jackfruit.top/2023/02/27/Zooker%E5%AE%89%E8%A3%85/",
            "url": "https://www.jackfruit.top/2023/02/27/Zooker%E5%AE%89%E8%A3%85/",
            "title": "Zooker安装",
            "date_published": "2023-02-27T03:36:51.000Z",
            "content_html": "<h1 id=\"zooker安装\"><a class=\"anchor\" href=\"#zooker安装\">#</a> zooker 安装</h1>\n<h3 id=\"一-解压\"><a class=\"anchor\" href=\"#一-解压\">#</a> 一、解压</h3>\n<pre><code>tar -zxvf zookeeper-3.4.6.tar.gz -C /opt/module\n</code></pre>\n<h3 id=\"二-修改配置文件\"><a class=\"anchor\" href=\"#二-修改配置文件\">#</a> 二、修改配置文件</h3>\n<pre><code>cd /opt/module/zookeeper-3.4.6\nmkdir data\ncd data\n</code></pre>\n<h4 id=\"vi-myid机器的id\"><a class=\"anchor\" href=\"#vi-myid机器的id\">#</a> vi myid\t机器的 ID</h4>\n<pre><code>填入 1\n</code></pre>\n<pre><code>cd /opt/module/zookeeper-3.4.6/conf\n\nmv zoo_sample.cfg zoo.cfg\t改名\n</code></pre>\n<h4 id=\"vi-zoocfg添加datadir的路径和添加server的配置\"><a class=\"anchor\" href=\"#vi-zoocfg添加datadir的路径和添加server的配置\">#</a> vi zoo.cfg\t添加 datadir 的路径和添加 server 的配置</h4>\n<pre><code>dataDir=/opt/module/zookeeper-3.4.6/data\nserver.1=master:2888:3888\nserver.2=slave1:2888:3888\nserver.3=slave2:2888:3888\n</code></pre>\n<h3 id=\"三-配置zookeeper环境变量\"><a class=\"anchor\" href=\"#三-配置zookeeper环境变量\">#</a> 三、配置 Zookeeper 环境变量</h3>\n<h4 id=\"vi-etcprofile\"><a class=\"anchor\" href=\"#vi-etcprofile\">#</a> vi /etc/profile</h4>\n<pre><code>#set zookeeper environment  \nexport ZOOKEEPER_HOME=/opt/module/zookeeper-3.4.6 \nexport PATH=$PATH:$ZOOKEEPER_HOME/bin \n</code></pre>\n<pre><code>source /etc/profile\t\t#生效环境变量\n</code></pre>\n<h3 id=\"四-同步到其它虚拟机\"><a class=\"anchor\" href=\"#四-同步到其它虚拟机\">#</a> 四、同步到其它虚拟机</h3>\n<pre><code>scp -r /opt/module/zookeeper-3.4.6 root@slave1:/opt/module \n\nscp -r /opt/module/zookeeper-3.4.6 root@slave2:/opt/module\n\nscp -r /etc/profile root@slave1:/etc/profile\n\nscp -r /etc/profile root@slave2:/etc/profile\n</code></pre>\n<pre><code>source /etc/profile\t\t#slave1和slave2都要执行\n</code></pre>\n<h3 id=\"五-修改分节点的myid文件\"><a class=\"anchor\" href=\"#五-修改分节点的myid文件\">#</a> 五、修改分节点的 myid 文件</h3>\n<pre><code>cd /opt/module/zookeeper-3.4.6/data\n</code></pre>\n<h4 id=\"vi-myid机器id\"><a class=\"anchor\" href=\"#vi-myid机器id\">#</a> vi myid\t机器 ID</h4>\n<pre><code>分别为2和3\n</code></pre>\n<h3 id=\"六-启动zookeeper每个节点都要进行\"><a class=\"anchor\" href=\"#六-启动zookeeper每个节点都要进行\">#</a> 六、启动 Zookeeper（每个节点都要进行）</h3>\n<pre><code>cd /opt/module/zookeeper-3.4.6/bin\n</code></pre>\n<pre><code>zkServer.sh start\t\t#开启服务\n</code></pre>\n<pre><code>zkServer.sh status\t\t#查看状态\n</code></pre>\n<p>注：一个节点是 Leader，其余的结点是 Follower（Leader 不一定是主节点，系统随机分配的）。</p>\n",
            "tags": [
                "Hadoop搭建",
                "搭建"
            ]
        },
        {
            "id": "https://www.jackfruit.top/2023/02/27/Sqoop%E5%AE%89%E8%A3%85/",
            "url": "https://www.jackfruit.top/2023/02/27/Sqoop%E5%AE%89%E8%A3%85/",
            "title": "Sqoop安装",
            "date_published": "2023-02-27T03:36:14.000Z",
            "content_html": "<h1 id=\"sqoop安装\"><a class=\"anchor\" href=\"#sqoop安装\">#</a> Sqoop 安装</h1>\n<h3 id=\"一-解压\"><a class=\"anchor\" href=\"#一-解压\">#</a> 一、解压</h3>\n<pre><code>tar -zxvf /opt/software/sqoop-1.4.2.bin__hadoop-2.0.0-alpha.tar.gz -C /opt/module\n</code></pre>\n<h3 id=\"二-配置profile文件\"><a class=\"anchor\" href=\"#二-配置profile文件\">#</a> 二、配置 profile 文件</h3>\n<p><strong>vi /etc/profile</strong></p>\n<pre><code>#sqoop\nexport SQOOP_HOME=/opt/module/sqoop-1.4.2.bin__hadoop-2.0.0-alpha\nexport PATH=$PATH:$ZOOKEEPER_HOME/bin:$SQOOP_HOME/bin\n</code></pre>\n<pre><code>source /etc/profile  (刷新profile文件)\n</code></pre>\n<p><strong>验证环境是否配置完成</strong></p>\n<pre><code>sqoop version\n</code></pre>\n<h3 id=\"三-修改sqoop-envsh文件\"><a class=\"anchor\" href=\"#三-修改sqoop-envsh文件\">#</a> 三、修改 sqoop-env.sh 文件</h3>\n<pre><code>cd /opt/module/sqoop-1.4.2.bin__hadoop-2.0.0-alpha/conf\n</code></pre>\n<pre><code>mv sqoop-env-template.sh sqoop-env.sh\nvi sqoop-env.sh\n</code></pre>\n<pre><code>#Set path to where bin/hadoop is available\nexport HADOOP_COMMON_HOME=/opt/module/hadoop-2.7.7\n\n#Set path to where hadoop-*-core.jar is available\nexport HADOOP_MAPRED_HOME=/opt/module/hadoop-2.7.7\n\n#set the path to where bin/hbase is available\nexport HBASE_HOME=\n\n#Set the path to where bin/hive is available\nexport HIVE_HOME=/opt/module/apache-hive-2.3.4-bin\n\n#Set the path for where zookeper config dir is\nexport ZOOCFGDIR=/opt/module/zookeeper-3.4.6/conf\n</code></pre>\n<h4 id=\"将mysql关系型数据库驱动包放到sqooplib目录下\"><a class=\"anchor\" href=\"#将mysql关系型数据库驱动包放到sqooplib目录下\">#</a> 将 mysql 关系型数据库驱动包放到 sqoop/lib 目录下</h4>\n<pre><code>cp /opt/software/mysql-connector-java-5.1.47-bin.jar /opt/module/sqoop-1.4.2.bin__hadoop-2.0.0-alpha/lib\n</code></pre>\n<h4 id=\"验证sqoop连接mysql数据库是否成功\"><a class=\"anchor\" href=\"#验证sqoop连接mysql数据库是否成功\">#</a> 验证 sqoop 连接 mysql 数据库是否成功</h4>\n<pre><code>sqoop list-databases --connect jdbc:mysql://master:3306 --username root --password 123456\n</code></pre>\n",
            "tags": [
                "Hadoop搭建",
                "搭建"
            ]
        },
        {
            "id": "https://www.jackfruit.top/2023/02/27/Spark%E5%AE%89%E8%A3%85/",
            "url": "https://www.jackfruit.top/2023/02/27/Spark%E5%AE%89%E8%A3%85/",
            "title": "Spark安装",
            "date_published": "2023-02-27T03:35:58.000Z",
            "content_html": "<h1 id=\"spark安装\"><a class=\"anchor\" href=\"#spark安装\">#</a> spark 安装</h1>\n<h3 id=\"一-解压\"><a class=\"anchor\" href=\"#一-解压\">#</a> 一、解压</h3>\n<pre><code>tar -zxvf /opt/software/spark-2.1.1-bin-hadoop2.7.tgz -C /opt/module\n</code></pre>\n<h3 id=\"二-配置spark-envsh文件\"><a class=\"anchor\" href=\"#二-配置spark-envsh文件\">#</a> 二、配置 spark-env.sh 文件</h3>\n<pre><code>mv /opt/module/spark-2.1.1-bin-hadoop2.7 spark-2.1.1\ncd /opt/module/spark-2.1.1/conf\ncp spark-env.sh.template spark-env.sh\n</code></pre>\n<p><strong>vi <span class=\"exturl\" data-url=\"aHR0cDovL3NwYXJrLWVudi5zaA==\">spark-env.sh</span></strong></p>\n<pre><code>export SPARK_MASTER_IP=master\nexport SPARK_WORKER_MEMORY=8g\nexport SCALA_HOME=/opt/module/scala-2.11.0\nexport JAVA_HOME=/opt/module/jdk1.8\nexport HADOOP_HOME=/opt/module/hadoop-2.7.7\nexport HADOOP_CONF_DIR=/opt/module/hadoop-2.7.7/etc/hadoop\n</code></pre>\n<h3 id=\"三-修改slaves文件\"><a class=\"anchor\" href=\"#三-修改slaves文件\">#</a> 三、修改 slaves 文件</h3>\n<pre><code>cp slaves.template slaves\n</code></pre>\n<p><strong>vi slaves</strong></p>\n<pre><code>master\nslave1\nslave2\n</code></pre>\n<h3 id=\"四-配置spark环境变量\"><a class=\"anchor\" href=\"#四-配置spark环境变量\">#</a> 四、配置 Spark 环境变量</h3>\n<p><strong>vi /etc/profile</strong></p>\n<pre><code>#spark\nexport SPARK_HOME=/opt/module/spark-2.1.1\nexport PATH=$PATH:$SPARK_HOME/bin\nexport PATH=$PATH:$SPARK_HOME/sbin\n</code></pre>\n<pre><code>source /etc/profile\t\t#生效环境变量\n</code></pre>\n<h3 id=\"五-同步其它虚拟机\"><a class=\"anchor\" href=\"#五-同步其它虚拟机\">#</a> 五、同步其它虚拟机</h3>\n<pre><code>scp -r /etc/profile root@slave1:/etc/profile\t#将环境变量profile文件分发到slave1节点\n\nscp -r /etc/profile root@slave2:/etc/profile\t#将环境变量profile文件分发到slave2节点\n\nscp -r /opt/module/spark-2.1.1 root@slave1:/opt/module\t#将scala文件分发到slave1节点\n\nscp -r /opt/module/spark-2.1.1 root@slave2:/opt/module\t#将scala文件分发到slave2节点\n</code></pre>\n<pre><code>source /etc/profile\t\t#slave1和slave2都要执行\n</code></pre>\n<h3 id=\"六-开启spark环境只在master节点\"><a class=\"anchor\" href=\"#六-开启spark环境只在master节点\">#</a> 六、开启 spark 环境（只在 master 节点）</h3>\n<pre><code>/opt/module/spark-2.1.1/sbin/start-all.sh\n</code></pre>\n<p>验证</p>\n<pre><code>http://192.168.23.48:8080\n</code></pre>\n",
            "tags": [
                "Hadoop搭建",
                "搭建"
            ]
        },
        {
            "id": "https://www.jackfruit.top/2023/02/27/scala%E5%AD%A6%E4%B9%A0/",
            "url": "https://www.jackfruit.top/2023/02/27/scala%E5%AD%A6%E4%B9%A0/",
            "title": "scala学习",
            "date_published": "2023-02-27T03:35:41.000Z",
            "content_html": "",
            "tags": [
                "学习",
                "搭建"
            ]
        },
        {
            "id": "https://www.jackfruit.top/2023/02/27/scala%E5%AE%89%E8%A3%85/",
            "url": "https://www.jackfruit.top/2023/02/27/scala%E5%AE%89%E8%A3%85/",
            "title": "scala安装",
            "date_published": "2023-02-27T03:35:27.000Z",
            "content_html": "<h1 id=\"scala安装\"><a class=\"anchor\" href=\"#scala安装\">#</a> scala 安装</h1>\n<h3 id=\"一-解压\"><a class=\"anchor\" href=\"#一-解压\">#</a> 一、解压</h3>\n<pre><code>tar -zxvf /opt/software/scala-2.11.0.tgz -C /opt/module \n</code></pre>\n<h3 id=\"二-配置环境\"><a class=\"anchor\" href=\"#二-配置环境\">#</a> 二、配置环境</h3>\n<pre><code>cd /opt/module/scala-2.11.0\n</code></pre>\n<p><strong>vi /etc/profile</strong></p>\n<pre><code>#set scala\nexport SCALA_HOME=/opt/module/scala-2.11.0\nexport PATH=$PATH:$SCALA_HOME/bin\n</code></pre>\n<pre><code>source /etc/profile\t\t#生效环境变量\n</code></pre>\n<pre><code>scala -version\t\t\t#查看scala是否安装成功\n</code></pre>\n<h3 id=\"三-同步其它虚拟机\"><a class=\"anchor\" href=\"#三-同步其它虚拟机\">#</a> 三、同步其它虚拟机</h3>\n<pre><code>scp -r /etc/profile root@slave1:/etc/profile\t#将环境变量profile文件分发到slave1节点\n\nscp -r /etc/profile root@slave2:/etc/profile\t#将环境变量profile文件分发到slave2节点\n\nscp -r /opt/module/scala-2.11.0 root@slave1:/opt/module\t\t#将scala文件分发到slave1节点\n\nscp -r /opt/module/scala-2.11.0 root@slave2:/opt/module\t\t#将scala文件分发到slave2节点\n</code></pre>\n<p><strong>(分节点)</strong></p>\n<pre><code>source /etc/profile\t\t#生效环境变量\n</code></pre>\n<pre><code>scala -version\t\t\t#查看scala是否安装成功\n</code></pre>\n",
            "tags": [
                "Hadoop搭建",
                "搭建"
            ]
        },
        {
            "id": "https://www.jackfruit.top/2023/02/27/MySQL%E8%8D%89%E7%A8%BF%E4%BD%BF%E7%94%A8/",
            "url": "https://www.jackfruit.top/2023/02/27/MySQL%E8%8D%89%E7%A8%BF%E4%BD%BF%E7%94%A8/",
            "title": "MySQL草稿使用",
            "date_published": "2023-02-27T03:35:06.000Z",
            "content_html": "<h2 id=\"mysql7条消息-基础篇数据库-sql-入门教程_lucifer三思而后行的博客-csdn博客_sql数据库\"><a class=\"anchor\" href=\"#mysql7条消息-基础篇数据库-sql-入门教程_lucifer三思而后行的博客-csdn博客_sql数据库\">#</a> MySQL（<span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzUwNTQ2MDE2L2FydGljbGUvZGV0YWlscy8xMjAwNzAwMDM/b3BzX3JlcXVlc3RfbWlzYz0lN0IlMjJyZXF1ZXN0JTVGaWQlMjIlM0ElMjIxNjY1NzA3OTY5MTY3ODI0MTcwMjQ2MDclMjIlMkMlMjJzY20lMjIlM0ElMjIyMDE0MDcxMy4xMzAxMDIzMzQuLiUyMiU3RCZhbXA7cmVxdWVzdF9pZD0xNjY1NzA3OTY5MTY3ODI0MTcwMjQ2MDcmYW1wO2Jpel9pZD0wJmFtcDt1dG1fbWVkaXVtPWRpc3RyaWJ1dGUucGNfc2VhcmNoX3Jlc3VsdC5ub25lLXRhc2stYmxvZy0yfmFsbH50b3BfcG9zaXRpdmV+ZGVmYXVsdC0xLTEyMDA3MDAwMy1udWxsLW51bGwuMTQyJTVFdjU2JTVFanNfdG9wLDIwMSU1RXYzJTVFY29udHJvbF8xJmFtcDt1dG1fdGVybT0lRTYlOTUlQjAlRTYlOEQlQUUlRTUlQkElOTMmYW1wO3NwbT0xMDE4LjIyMjYuMzAwMS40MTg3\">(7 条消息) 基础篇：数据库 SQL 入门教程_Lucifer 三思而后行的博客 - CSDN 博客_sql 数据库</span>）</h2>\n<pre><code>create database company;\t#创建数据库\n\nshow databases;\t#查看数据库\n\nuse company;\t#使用数据库\n\nshow tables;\t#查看所有表\n\ndesc XXX;\t#查看表结构\n\n#创建表\ncreate table company.staff(\nid int (4) primary key not null auto_increment,\nname varchar(255),\nsex varchar(255)\n);\n\n#查看表\nselect * from staff;\n\n#插入数据\ninsert into staff(name,sex) values('Thomas','Male');\n\n#插入数据到表格\ninsert into staff values(2,'Catalina','FeMale');\n\n#删除表\ndrop table staff;\n\n#删除表数据\ndelete from staff where name='Thomas';\n\n#修改表名\nalter table XXXX rename to XXXX;\n</code></pre>\n<h2 id=\"使用sqoop上传到hdfs\"><a class=\"anchor\" href=\"#使用sqoop上传到hdfs\">#</a> 使用 sqoop 上传到 hdfs</h2>\n<h3 id=\"模板\"><a class=\"anchor\" href=\"#模板\">#</a> 模板</h3>\n<pre><code>[root@master sqoop-1.4.7]# bin/sqoop import \\\n--connect jdbc:mysql://master:3306/company \\ #MySQL数据库的数据库端口和数据库名称\n--username root \\ #mysql数据库用户\n--password 000000 \\ #mysql密码\n--table staff \\ #mysql中的表名\n--target-dir /user/company \\ #导入到hdfs上的位置\n--delete-target-dir \\ #如果存在相同文件夹删除\n--fields-terminated-by &quot;\\t&quot; #按\\t分割\n\n\n#参数解释\n--delete-target-dir ：目标目录存在就删除\n--target-dir：指定输出目录，不指定就直接在主目录下生产。\n--num-mappers 1：设置map的个数\n--direct：manager.DirectMySQLManager: Beginning mysqldump fast path import.使用这个命令会很快，本机装有mysql时，才可以使用。\n--fields-terminated-by &quot;\\t&quot;：设置输出文件分分割方式\n--as-parquetfile :设置文件格式为parquetfile\n--split-by id :通常配合-m 参数使用。用于指定根据哪个字段进行划分并启动多少个maptask。\n--columns &lt;col,col,col...&gt; ：指定表中部分字段进行导入\n--query：直接查询\n--where &lt;where clause&gt; ：条件查询\n</code></pre>\n<p><strong>全部导入</strong></p>\n<pre><code>bin/sqoop import --connect jdbc:mysql://192.168.128.160:3306/company --username root --password 123456 --table staff --target-dir /user/company --fields-terminated-by &quot;\\t&quot; --delete-target-dir\n</code></pre>\n<p><strong>查询导入</strong></p>\n<pre><code>bin/sqoop import --connect jdbc:mysql://192.168.182.10:3306/company --username root --password 123456 --table staff --target-dir /user/company --fields-terminated-by &quot;\\t&quot; --query 'select name,sex from staff where id &lt;=1 and $CONDITIONS;'\n</code></pre>\n<p><strong>删除导入</strong></p>\n<pre><code>hadoop fs -rm -r /user/company\n</code></pre>\n<p><strong>查看导入</strong></p>\n<pre><code>hdfs dfs -cat /user/company/part-m-00000\n</code></pre>\n<p><strong>导入指定列</strong></p>\n<pre><code>--columns id,sex \\ #列名\n</code></pre>\n<h2 id=\"从mysql导入到hive\"><a class=\"anchor\" href=\"#从mysql导入到hive\">#</a> 从 MySQL 导入到 hive</h2>\n<p><strong>全局导入</strong></p>\n<pre><code>bin/sqoop import \\\n--connect jdbc:mysql://master:3306/company \\\n--username root \\\n--password 123456 \\\n--table staff \\\n--num-mappers 1 \\\n--hive-import \\ #导入hive的关键字\n--fields-terminated-by &quot;\\t&quot; \\\n--hive-overwrite \\ \n--hive-table staff_hive \\\t#hive的表名\n--hive-database ods\t#导入到hive的数据库\n\nbin/sqoop import --connect jdbc:mysql://master:3306/company --username root --password 123456 --table user_info --num-mappers 1 --hive-import --fields-terminated-by &quot;\\t&quot; --hive-overwrite --hive-table ods.user_info\n</code></pre>\n<p><strong>增量导入</strong></p>\n<pre><code>添加\n--incremental lastmodified \\\n--check-column insert_time \\\n--last-value &quot;2019-03-09 14:59:21&quot; \\\n\n--incremental\t指定增量模式，可选append或者lastmodified，append不能用于hive\n--check-column\t指定检查的列，也就是参考的增量列\n--last-value\t指定增量列的最新数据\n--merge-key\t指定参考的需要合并的列\n\n\n条件导入\nwhere，条件导入\n--where &quot;XXX&gt;XXX&quot;\n\ncolumns,指定导入指定列\n--columns XXX，XXX\n\nquery,导入查询结果\n--query ’‘\n\n\n</code></pre>\n<h2 id=\"从hdfs下载到mysql先把mysql表格数据清空\"><a class=\"anchor\" href=\"#从hdfs下载到mysql先把mysql表格数据清空\">#</a> 从 hdfs 下载到 MySQL\t(先把 MySQL 表格数据清空)</h2>\n<pre><code>#查看表\nselect * from XXXX;\n#删除表数据\ndelete from staff where name='XXXX';\n</code></pre>\n<p>脚本文件\tXXX.opt</p>\n<pre><code>export\n--connect\njdbc:mysql://master:3306/company\n--username\nroot\n--password\n123456\n--table\t//数据库表名\nstaff\n--num-mappers\n1\n--export-dir\t//hdfs文件的位置\n/user/company\n--input-fields-terminated-by\t\n&quot;\\t&quot;\n</code></pre>\n<h2 id=\"hadoop杀死正在运行的进程\"><a class=\"anchor\" href=\"#hadoop杀死正在运行的进程\">#</a> Hadoop 杀死正在运行的进程</h2>\n<pre><code>hadoop job -list\t# 查看当前任务列表\nhadoop job -kill job_id\t# 杀掉某一任务\n</code></pre>\n<pre><code>CREATE TABLE user_info (\n    id INT AUTO_INCREMENT PRIMARY KEY,\n    first_name VARCHAR(50) NOT NULL,\n    last_name VARCHAR(50) NOT NULL,\n    birth_date DATE NOT NULL\n);\n\nCREATE TABLE user_info (\n    id INT AUTO_INCREMENT PRIMARY KEY,\n    first_name VARCHAR(50) NOT NULL,\n    last_name VARCHAR(50) NOT NULL,\n    birth_date DATE NOT NULL\n);\n</code></pre>\n<h3 id=\"mysql创建临时表\"><a class=\"anchor\" href=\"#mysql创建临时表\">#</a> MySQL 创建临时表</h3>\n",
            "tags": [
                "学习",
                "学习MySQL"
            ]
        },
        {
            "id": "https://www.jackfruit.top/2023/02/27/Kafka%E5%AE%89%E8%A3%85/",
            "url": "https://www.jackfruit.top/2023/02/27/Kafka%E5%AE%89%E8%A3%85/",
            "title": "Kafka安装",
            "date_published": "2023-02-27T03:34:36.000Z",
            "content_html": "<h1 id=\"kafka安装\"><a class=\"anchor\" href=\"#kafka安装\">#</a> Kafka 安装</h1>\n<h3 id=\"1-解压\"><a class=\"anchor\" href=\"#1-解压\">#</a> 1、解压</h3>\n<pre><code>tar -zxvf /opt/software/kafka_2.11-2.0.0.tgz -C /opt/module\n</code></pre>\n<h3 id=\"2-修改配置文件\"><a class=\"anchor\" href=\"#2-修改配置文件\">#</a> 2、修改配置文件</h3>\n<pre><code>cd /opt/module/kafka_2.11-2.0.0\nmkdir logs\t运行日志存放的路径\ncd config\n</code></pre>\n<p><strong>vi server.properties</strong></p>\n<pre><code>#broker的全局唯一编号，不能重复\nbroker.id=0\t\t#需要操作，每台机器id号不一样\n#删除topic的功能使能\ndelete.topic.enable=true\t#需要操作\n#kafka运行日志存放的路径\nlog.dirs=/opt/module/kafka_2.11-2.0.0/logs\t\t#需要操作\n#配置zookeeper集群地址\nzookeeper.connect=master:2181,slave1:2181,slave2:2181\t\t#需要操作\n</code></pre>\n<h3 id=\"3-配置环境变量\"><a class=\"anchor\" href=\"#3-配置环境变量\">#</a> 3、配置环境变量</h3>\n<p><strong>vi /etc/profile</strong></p>\n<pre><code>#set kakfa\nexport KAFKA_HOME=/opt/module/kafka_2.11-2.0.0\nexport PATH=$PATH:$KAFKA_HOME/bin\n</code></pre>\n<pre><code>source /etc/profile\t\t#生效环境变量\n</code></pre>\n<h3 id=\"四-同步其他虚拟机\"><a class=\"anchor\" href=\"#四-同步其他虚拟机\">#</a> 四、同步其他虚拟机</h3>\n<pre><code>scp -r /etc/profile root@slave1:/etc/profile\t#将环境变量profile文件分发到slave1节点\nscp -r /etc/profile root@slave2:/etc/profile\t#将环境变量profile文件分发到slave2节点\nscp -r /opt/module/kafka_2.11-2.0.0 root@slave1:/opt/module\t#将kafka文件分发到slave1节点\nscp -r /opt/module/kafka_2.11-2.0.0 root@slave2:/opt/module\t#将kafka文件分发到slave2节点\n</code></pre>\n<pre><code>source /etc/profile\t\t#分节点生效环境变量\n</code></pre>\n<h3 id=\"五-修改分节点的serverproperties文件\"><a class=\"anchor\" href=\"#五-修改分节点的serverproperties文件\">#</a> 五、修改分节点的<strong> server.properties 文件</strong></h3>\n<p><strong>vi /opt/module/kafka_2.11-2.0.0/config/server.properties</strong></p>\n<pre><code>broker.id=1\t\tslave1\n</code></pre>\n<pre><code>broker.id=2\t\tslave2\n</code></pre>\n<h3 id=\"六-启动\"><a class=\"anchor\" href=\"#六-启动\">#</a> 六、启动</h3>\n<p><strong>先启动 zookeeper（三台机器一起）</strong></p>\n<pre><code>cd /opt/module/zookeeper-3.4.6\t\t#先进入zookeeper的目录\nbin/zkServer.sh start\t\t#三台机器启动zookeeper\nbin/zkServer.sh status\t\t#查看启动状态\n</code></pre>\n<p>一个节点是 Leader，其余的结点是 Follower（Leader 不一定是主节点，系统随机分配的），即 zookeeper 启动成功！</p>\n<p><strong>启动 kafka (三台机器一起)</strong></p>\n<pre><code>cd /opt/module/kafka_2.11-2.0.0\n</code></pre>\n<pre><code>bin/kafka-server-start.sh config/server.properties &amp;\n</code></pre>\n<p>按一下 enter</p>\n<p>都有 kafka 进程表示成功</p>\n<h3 id=\"七-创建topic\"><a class=\"anchor\" href=\"#七-创建topic\">#</a> 七、创建 topic</h3>\n<pre><code>2.2版本以上用这个\nkafka-topics.sh --create --bootstrap-server master:9092,slave1:9092,slave2:9092 --replication-factor 2 --partitions 2 --topic installtopic\n</code></pre>\n<pre><code>kafka-topics.sh --create --zookeeper master:2181,slave1:2181,slave2:2181 --replication-factor 2 --partitions 2 --topic installtopic\n</code></pre>\n<p>查看指定的 topic</p>\n<pre><code>kafka-topics.sh --describe --zookeeper master:2181,slave1:2181,slave2:2181 --topic installtopic\n</code></pre>\n<p>查看所有可用 topic</p>\n<pre><code>kafka-topics.sh --list --zookeeper master:2181,slave1:2181,slave2:2181\n</code></pre>\n",
            "tags": [
                "Hadoop搭建",
                "搭建"
            ]
        },
        {
            "id": "https://www.jackfruit.top/2023/02/27/java%E5%AE%89%E8%A3%85/",
            "url": "https://www.jackfruit.top/2023/02/27/java%E5%AE%89%E8%A3%85/",
            "title": "java安装",
            "date_published": "2023-02-27T03:34:09.000Z",
            "content_html": "<h1 id=\"java安装\"><a class=\"anchor\" href=\"#java安装\">#</a> java 安装</h1>\n<h2 id=\"解压\"><a class=\"anchor\" href=\"#解压\">#</a> 解压</h2>\n<pre><code>tar -zxf jdk-8u212-linux-x64.tar.gz -C /opt/module/\n</code></pre>\n<h2 id=\"配置环境变量\"><a class=\"anchor\" href=\"#配置环境变量\">#</a> 配置环境变量</h2>\n<p>vi /etc/profi</p>\n<pre><code># java envirment\nexport JAVA_HOME=/opt/module/jdk1.8.0_212\nexport PATH=$PATH:$JAVA_HOME/bin\n</code></pre>\n<h2 id=\"使其生效\"><a class=\"anchor\" href=\"#使其生效\">#</a> 使其生效</h2>\n<pre><code>source /etc/profile\n</code></pre>\n<h2 id=\"测试\"><a class=\"anchor\" href=\"#测试\">#</a> 测试</h2>\n<pre><code>java -version\n\njavac\n</code></pre>\n",
            "tags": [
                "Hadoop搭建",
                "搭建"
            ]
        },
        {
            "id": "https://www.jackfruit.top/2023/02/27/hive%E4%BD%BF%E7%94%A8/",
            "url": "https://www.jackfruit.top/2023/02/27/hive%E4%BD%BF%E7%94%A8/",
            "title": "hive使用",
            "date_published": "2023-02-27T03:33:46.000Z",
            "content_html": "<h2 id=\"hive的使用\"><a class=\"anchor\" href=\"#hive的使用\">#</a> hive 的使用</h2>\n<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cueWlpYmFpLmNvbS9oaXZlL2hpdmVfYWx0ZXJfdGFibGUuaHRtbA==\">Hive 修改表 - Hive 教程 (yiibai.com)</span></p>\n<p>查看库</p>\n<pre><code>show databases;\n</code></pre>\n<p>创建库</p>\n<pre><code>create schema xxxx；\n</code></pre>\n<p>删除库</p>\n<pre><code>drop database if exists XXX;\n</code></pre>\n<p>查看所有表</p>\n<pre><code>show tables;\n</code></pre>\n<p>创建表</p>\n<pre><code>create table if not exists XXX(数据类型\n)\n</code></pre>\n<p>修改表</p>\n<pre><code>\n</code></pre>\n<p>删除表</p>\n<pre><code>drop table if exists XXXX;\n</code></pre>\n<p>查看分区表结构</p>\n<pre><code>desc formatted 表名;\n</code></pre>\n<p>在 spark 运行打包程序</p>\n<pre><code>bin/spark-submit --class Text01.test1 --master spark://master:7077 --conf spark.sql.catalogImplementation=hive /opt/spark_demo.jar 10\t\n</code></pre>\n<p>创建静态分区</p>\n<pre><code>create table user_info(\n    id int,\n    name string,\n    operate_time date,\n    create_time date)\n    partitioned by (day string)\n    row format delimited\n    fields terminated by '/t';\n</code></pre>\n<p>静态分区写入数据</p>\n<pre><code>--1、静态分区设置\ninsert overwrite table user_info partition (day='2022-11-01')\nselect id,name,operate_time,create_time\t\nfrom user_info1 \nwhere create_time='2022-11-01';\n\n--2、查看分区\nshow partitions user_info;\n\n--3、查看udata_partition数据\nselect * from user_info; \n\n</code></pre>\n",
            "tags": [
                "Hadoop搭建",
                "搭建"
            ]
        },
        {
            "id": "https://www.jackfruit.top/2023/02/27/hive%E5%92%8Cmysql%E5%AE%89%E8%A3%85/",
            "url": "https://www.jackfruit.top/2023/02/27/hive%E5%92%8Cmysql%E5%AE%89%E8%A3%85/",
            "title": "hive和mysql安装",
            "date_published": "2023-02-27T03:33:20.000Z",
            "content_html": "<h1 id=\"hive和mysql安装\"><a class=\"anchor\" href=\"#hive和mysql安装\">#</a> hive 和 mysql 安装</h1>\n<h3 id=\"一-解压-注意hive只需要在master节点上安装配置\"><a class=\"anchor\" href=\"#一-解压-注意hive只需要在master节点上安装配置\">#</a> 一、解压（# 注意：Hive 只需要在 master 节点上安装配置）</h3>\n<pre><code>cd  /opt/software\ntar -zxvf apache-hive-2.3.4-bin.tar.gz -C /opt/module\n</code></pre>\n<h3 id=\"二-安装mysql\"><a class=\"anchor\" href=\"#二-安装mysql\">#</a> 二、安装 mysql</h3>\n<p><strong>先卸载 mysql</strong></p>\n<pre><code>\t查看本机\trpm -qa | grep mariadb\n</code></pre>\n<pre><code>\t卸载\trpm -e --nodeps XXXXXXXXXX\n</code></pre>\n<p><strong>安装</strong></p>\n<pre><code>tar -xvf mysql-5.7.20-1.el6.x86_64.rpm-bundle.tar -C /opt/module\n\ncd /opt/module\n\nrpm -ivh mysql-community-common-5.7.20-1.el6.x86_64.rpm\n\nrpm -ivh mysql-community-libs-5.7.20-1.el6.x86_64.rpm\n\nrpm -ivh mysql-community-client-5.7.20-1.el6.x86_64.rpm\n\nrpm -ivh mysql-community-server-5.7.20-1.el6.x86_64.rpm --force --nodeps\n</code></pre>\n<p><em><strong>* 检查一下 *</strong></em></p>\n<pre><code>rpm -qa | grep mysql\n</code></pre>\n<p><em><strong>* 启动服务 *</strong></em></p>\n<pre><code>systemctl daemon-reload\t#重载所有修改过的配置文件\n\nsystemctl start mysqld\t#开启服务\n\nsystemctl enable mysqld #开机自启 若不成功也不影响\n</code></pre>\n<p><em><strong>* 登录 MySQL 数据库 *</strong></em></p>\n<pre><code>grep &quot;temporary password&quot; /var/log/mysqld.log\t #获取初密码\n\nmysql -uroot -p\t#登陆MySQL（注意中英文）\n</code></pre>\n<p><em><strong>*MySQL 密码安全策略设置 *</strong></em></p>\n<pre><code>set global validate_password_policy=0; #设置密码强度为低级\n\nset global validate_password_length=4;\t#设置密码长度\n\nalter user 'root'@'localhost' identified by '123456';\t#修改用户密码\n\n\\q\t#退出\n</code></pre>\n<p><em><strong>* 设置远程登录 *</strong></em></p>\n<pre><code>mysql -uroot -p123456\t#以新密码登陆MySQL\n\ncreate user 'root'@'%' identified by '123456';\t#创建用户\n\ngrant all privileges on *.* to 'root'@'%' with grant option;\t#***\\*允许远程连接\\****\n\nflush privileges;\t#刷新权限\n\ncreate database if not exists test;\t\t#创建数据库test\n\n\\q\n</code></pre>\n<h3 id=\"第二种方式\"><a class=\"anchor\" href=\"#第二种方式\">#</a> 第二种方式</h3>\n<p><strong>解压并改名</strong></p>\n<pre><code>tar -zxvf /opt/software/mysql-5.7.30-linux-glibc2.12-x86_64.tar.gz -C /opt/module\n\nmv mysql-5.7.30-linux-glibc2.12-x86_64 mysql\n</code></pre>\n<p><strong>创建数据目录并赋予权限</strong></p>\n<pre><code>mkdir -p  /data/mysql              #创建目录\nchown mysql:mysql -R /data/mysql   #赋予权限\n</code></pre>\n<p><strong>配置 my.cnf</strong>\t(新文件)</p>\n<p><strong>vi /etc/my.cnf</strong></p>\n<pre><code>[mysqld]\nbind-address=0.0.0.0\nport=3306\nuser=mysql\nbasedir=/opt/module/mysql\ndatadir=/data/mysql\nsocket=/tmp/mysql.sock\nlog-error=/data/mysql/mysql.err\npid-file=/data/mysql/mysql.pid\n#character config\ncharacter_set_server=utf8mb4\nsymbolic-links=0\nexplicit_defaults_for_timestamp=true\n</code></pre>\n<p>进入 MySQL 的 bin 目录</p>\n<pre><code>cd /opt/module/mysql/bin\n</code></pre>\n<p>初始化</p>\n<pre><code>./mysqld --defaults-file=/etc/my.cnf --basedir=/opt/module/mysql/ --datadir=/data/mysql/ --user=mysql --initialize\n</code></pre>\n<p>查看密码</p>\n<pre><code>cat /data/mysql/mysql.err\n</code></pre>\n<p>先将 mysql.server 放置到 /etc/init.d/mysql 中</p>\n<pre><code>cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysql\n</code></pre>\n<p>启动</p>\n<pre><code>service mysql start\n\nps -ef|grep mysql\n\n./mysql -u root -p   #bin目录下\n</code></pre>\n<p>再执行</p>\n<pre><code>SET PASSWORD = PASSWORD('123456');\nALTER USER 'root'@'localhost' PASSWORD EXPIRE NEVER;\nFLUSH PRIVILEGES;  \n\\q\n</code></pre>\n<p>再登陆</p>\n<pre><code>use mysql                                            #访问mysql库\nupdate user set host = '%' where user = 'root';      #使root能再任何host访问\nFLUSH PRIVILEGES;                                    #刷新\n</code></pre>\n<h3 id=\"三-修改配置文件\"><a class=\"anchor\" href=\"#三-修改配置文件\">#</a> 三、修改配置文件</h3>\n<p>配置环境文件</p>\n<h4 id=\"vi-etcprofile\"><a class=\"anchor\" href=\"#vi-etcprofile\">#</a> vi /etc/profile</h4>\n<pre><code>#set hive\nexport HIVE_HOME=/opt/module/apache-hive-2.3.4-bin\nexport PATH=$PATH:$HIVE_HOME/bin\n</code></pre>\n<pre><code>source  /etc/profile\n</code></pre>\n<h4 id=\"将mysql依赖包放入master中\"><a class=\"anchor\" href=\"#将mysql依赖包放入master中\">#</a> 将 mysql 依赖包放入 master 中</h4>\n<h4 id=\"修改文件\"><a class=\"anchor\" href=\"#修改文件\">#</a> 修改文件</h4>\n<pre><code>mkdir /opt/module/apache-hive-2.3.4-bin/warehouse\n\ncd /opt/module/apache-hive-2.3.4-bin/conf\n</code></pre>\n<h5 id=\"vi-hive-sitexml\"><a class=\"anchor\" href=\"#vi-hive-sitexml\">#</a> vi hive-site.xml</h5>\n<pre><code>&lt;configuration&gt;\n&lt;!-- Hive产生的元数据存放位置--&gt;\n&lt;property&gt;\n&lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;\n&lt;value&gt;/opt/module/apache-hive-2.3.4-bin/warehouse&lt;/value&gt;\n&lt;/property&gt;\n&lt;!-- 数据库连接JDBC的URL地址--&gt;\n&lt;property&gt;\n&lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; \n&lt;value&gt;jdbc:mysql://master:3306/hive?createDatabaseIfNotExist=true&amp;amp;useSSL=false&lt;/value&gt;\n&lt;/property&gt;\n&lt;!-- 数据库连接driver，即MySQL驱动--&gt;\n&lt;property&gt;\n&lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;\n&lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;\n&lt;/property&gt;\n&lt;!-- MySQL数据库用户名--&gt;\n&lt;property&gt;\n&lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;\n&lt;value&gt;root&lt;/value&gt;\n&lt;/property&gt;\n&lt;!-- MySQL数据库密码--&gt;\n&lt;property&gt;\n&lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;\n&lt;value&gt;123456&lt;/value&gt;\n&lt;/property&gt;\n&lt;property&gt;\n&lt;name&gt;hive.metastore.schema.verification&lt;/name&gt;\n&lt;value&gt;false&lt;/value&gt;\n&lt;/property&gt;\n&lt;property&gt;\n&lt;name&gt;datanucleus.schema.autoCreateAll&lt;/name&gt;\n&lt;value&gt;true&lt;/value&gt;\n&lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre>\n<h3 id=\"四-修改环境变量\"><a class=\"anchor\" href=\"#四-修改环境变量\">#</a> 四、修改环境变量</h3>\n<pre><code>cd /opt/module/apache-hive-2.3.4-bin/conf\n\nmv hive-env.sh.template hive-env.sh\n</code></pre>\n<h4 id=\"vi-hive-envsh\"><a class=\"anchor\" href=\"#vi-hive-envsh\">#</a> vi <span class=\"exturl\" data-url=\"aHR0cDovL2hpdmUtZW52LnNo\">hive-env.sh</span></h4>\n<pre><code>HADOOP_HOME=/opt/module/hadoop-2.7.7\nexport HIVE_CONF_DIR=/opt/module/apache-hive-2.3.4-bin/conf\n</code></pre>\n<pre><code>schematool -initSchema -dbType mysql\t初始化mysql\n</code></pre>\n<h3 id=\"五-启动mysql和hive\"><a class=\"anchor\" href=\"#五-启动mysql和hive\">#</a> 五、启动 Mysql 和 Hive</h3>\n<h4 id=\"启动hadoop集群只master上\"><a class=\"anchor\" href=\"#启动hadoop集群只master上\">#</a> 启动 hadoop 集群（只 master 上）</h4>\n<pre><code>cd /opt/module/hadoop-2.7.7\nsbin/start-all.sh\n</code></pre>\n<h4 id=\"元数据初始化命令\"><a class=\"anchor\" href=\"#元数据初始化命令\">#</a> 元数据初始化命令</h4>\n<pre><code>schematool -dbType mysql -initSchema\n</code></pre>\n<h4 id=\"启动hive-client只master上\"><a class=\"anchor\" href=\"#启动hive-client只master上\">#</a> 启动 hive client (只 master 上)</h4>\n<pre><code>cd /opt/module/apache-hive-2.3.4-bin\nbin/hive --service metastore &amp;\nbin/hive\n</code></pre>\n<p><strong>将 MySQL 驱动复制到 java 的 jre 下的 lib 下的 ext 目录下</strong></p>\n<pre><code>\n</code></pre>\n<h3 id=\"六-测试hive是否启动成功\"><a class=\"anchor\" href=\"#六-测试hive是否启动成功\">#</a> 六、测试 hive 是否启动成功</h3>\n<h4 id=\"查看数据库\"><a class=\"anchor\" href=\"#查看数据库\">#</a> 查看数据库</h4>\n<pre><code>hive&gt;show databases;\n</code></pre>\n<h4 id=\"创建数据库\"><a class=\"anchor\" href=\"#创建数据库\">#</a> 创建数据库</h4>\n<pre><code>hive&gt;create database testbase;\n</code></pre>\n<h4 id=\"复制一个master会话查看一下master进程\"><a class=\"anchor\" href=\"#复制一个master会话查看一下master进程\">#</a> 复制一个 master 会话，查看一下 master 进程</h4>\n<pre><code>如果可以查看以及建立数据库，进程中有RunJar进程，则代表Mysql和Hive安装成功啦~\n</code></pre>\n<h3 id=\"解决版本冲突问题slave1-操作\"><a class=\"anchor\" href=\"#解决版本冲突问题slave1-操作\">#</a> 解决版本冲突问题 (slave1 操作)</h3>\n<pre><code>cp /opt/module/apache-hive-2.3.4-bin/lib/jline-2.12.jar /opt/module/hadoop-2.7.7/share/hadoop/yarn/lib\n</code></pre>\n",
            "tags": [
                "Hadoop搭建",
                "搭建"
            ]
        },
        {
            "id": "https://www.jackfruit.top/2023/02/27/hadoop-%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/",
            "url": "https://www.jackfruit.top/2023/02/27/hadoop-%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/",
            "title": "hadoop 伪分布式安装配置",
            "date_published": "2023-02-27T03:32:26.000Z",
            "content_html": "<h2 id=\"在伪分布式里我们只需要改三个配置文件\"><a class=\"anchor\" href=\"#在伪分布式里我们只需要改三个配置文件\">#</a> 在伪分布式里我们只需要改三个配置文件</h2>\n<h3 id=\"core-sitexml\"><a class=\"anchor\" href=\"#core-sitexml\">#</a> core-site.xml</h3>\n<p>文件包含了 NameNode 主机地址，监听端口等信息，对于这个伪分布式模型来说，我的主机地址为 master，NameNode 默认使用的端口为 9000。</p>\n<pre><code>&lt;configuration&gt;\n&lt;!-- 指定HDFS中NameNode的地址 --&gt;\n&lt;property&gt;\n &lt;name&gt;fs.defaultFS&lt;/name&gt;\n &lt;value&gt;hdfs://master:9000&lt;/value&gt;\n&lt;/property&gt;\n &lt;!-- 指定hadoop运行时产生文件的存储目录 --&gt;\n&lt;property&gt;\n &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;\n &lt;value&gt;/opt/module/hadoop-2.7.7/tmp&lt;/value&gt;\n&lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre>\n<h3 id=\"hdfs-sitexml\"><a class=\"anchor\" href=\"#hdfs-sitexml\">#</a> hdfs-site.xml</h3>\n<p>用于配置 / HDFS 的相关属性，例如数据块的副本参数，数据块的副本对于伪分布式来说应该为 1</p>\n<pre><code>&lt;configuration&gt;\n&lt;!-- 指定HDFS副本的数量 --&gt;\n   &lt;property&gt;\n      &lt;name&gt;dfs.replication&lt;/name&gt;\n      &lt;value&gt;1&lt;/value&gt;\n   &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre>\n<h3 id=\"hadoop-envsh\"><a class=\"anchor\" href=\"#hadoop-envsh\">#</a> <span class=\"exturl\" data-url=\"aHR0cDovL2hhZG9vcC1lbnYuc2g=\">hadoop-env.sh</span></h3>\n<p>由于 Hadoop 是 java 进程，所以需要添加 jdk</p>\n<pre><code>export JAVA_HOME=/opt/module/jdk1.8\n</code></pre>\n<h2 id=\"格式化数据\"><a class=\"anchor\" href=\"#格式化数据\">#</a> 格式化数据</h2>\n<pre><code>hdfs namenode -format\n</code></pre>\n<h2 id=\"启动集群\"><a class=\"anchor\" href=\"#启动集群\">#</a> 启动集群</h2>\n<pre><code>sbin/start-all.sh\n</code></pre>\n<h2 id=\"查看集群\"><a class=\"anchor\" href=\"#查看集群\">#</a> 查看集群</h2>\n<pre><code>jps\n\nhttp://192.168.23.48:50070\n</code></pre>\n",
            "tags": [
                "Hadoop搭建",
                "搭建"
            ]
        },
        {
            "id": "https://www.jackfruit.top/2023/02/27/hadoop-%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/",
            "url": "https://www.jackfruit.top/2023/02/27/hadoop-%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/",
            "title": "hadoop 完全分布式安装配置",
            "date_published": "2023-02-27T03:31:22.000Z",
            "content_html": "<h1 id=\"完全分布式安装hadoop\"><a class=\"anchor\" href=\"#完全分布式安装hadoop\">#</a> 完全分布式安装 hadoop</h1>\n<h3 id=\"1-新建optsoftware-使用xftp将hadoop和java的压缩包上传\"><a class=\"anchor\" href=\"#1-新建optsoftware-使用xftp将hadoop和java的压缩包上传\">#</a> 1、新建 /opt/software 使用 xftp 将 hadoop 和 java 的压缩包上传</h3>\n<pre><code>cd /opt/\nmkdir software\n</code></pre>\n<h3 id=\"2-新建module文件夹存放解压后的hadoop\"><a class=\"anchor\" href=\"#2-新建module文件夹存放解压后的hadoop\">#</a> 2、新建 module 文件夹存放解压后的 hadoop</h3>\n<pre><code>mkdir module\n</code></pre>\n<h3 id=\"3-解压hadoop\"><a class=\"anchor\" href=\"#3-解压hadoop\">#</a> 3、解压 hadoop</h3>\n<pre><code>cd /opt/software\ntar -zxf hadoop-2.7.7.tar.gz -C /opt/module/\n</code></pre>\n<h3 id=\"4-配置环境\"><a class=\"anchor\" href=\"#4-配置环境\">#</a> 4、配置环境</h3>\n<h4 id=\"vi-etcprofile\"><a class=\"anchor\" href=\"#vi-etcprofile\">#</a> vi /etc/profile</h4>\n<pre><code>#hadoop\nexport HADOOP_HOME=/opt/module/hadoop-2.7.7\nexport PATH=$PATH:$HADOOP_HOME/bin\nexport PATH=$PATH:$HADOOP_HOME/sbin\n</code></pre>\n<h3 id=\"5-使其生效\"><a class=\"anchor\" href=\"#5-使其生效\">#</a> 5、使其生效</h3>\n<pre><code>source /etc/profile\n</code></pre>\n<h3 id=\"6-验证\"><a class=\"anchor\" href=\"#6-验证\">#</a> 6、验证</h3>\n<pre><code>hadoop version\n</code></pre>\n<h3 id=\"7-配置hadoop文件\"><a class=\"anchor\" href=\"#7-配置hadoop文件\">#</a> 7、配置 hadoop 文件</h3>\n<h4 id=\"vi-core-sitexml\"><a class=\"anchor\" href=\"#vi-core-sitexml\">#</a> vi core-site.xml</h4>\n<pre><code>&lt;configuration&gt;\n&lt;!-- 指定HDFS中NameNode的地址 --&gt;\n&lt;property&gt;\n &lt;name&gt;fs.defaultFS&lt;/name&gt;\n &lt;value&gt;hdfs://master:9000&lt;/value&gt;\n&lt;/property&gt;\n &lt;!-- 指定hadoop运行时产生文件的存储目录 --&gt;\n&lt;property&gt;\n &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;\n &lt;value&gt;/opt/module/hadoop-2.7.7/tmp&lt;/value&gt;\n&lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre>\n<h4 id=\"vi-hdfs-sitexml\"><a class=\"anchor\" href=\"#vi-hdfs-sitexml\">#</a> vi hdfs-site.xml</h4>\n<pre><code>&lt;configuration&gt;\n &lt;property&gt;\n\t&lt;name&gt;dfs.replication&lt;/name&gt;\n  \t&lt;value&gt;3&lt;/value&gt;\n &lt;/property&gt;\n &lt;property&gt;\n  \t&lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;\n\t&lt;value&gt;slave1:50090&lt;/value&gt;\n &lt;/property&gt;\n &lt;property&gt;\n\t&lt;name&gt;dfs.data.dir&lt;/name&gt;\n\t&lt;value&gt;/opt/module/hadoop-2.7.7/tmp/data&lt;/value&gt;\n &lt;/property&gt;\n &lt;property&gt;\n\t&lt;name&gt;dfs.name.dir&lt;/name&gt;\n\t&lt;value&gt;/opt/module/hadoop-2.7.7/tmp/name&lt;/value&gt;\n &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre>\n<p><em><strong>* 配置文件 slaves slaves 文件里面记录的是集群里所有 DataNode 的主机名 *</strong></em></p>\n<h4 id=\"vi-slaves\"><a class=\"anchor\" href=\"#vi-slaves\">#</a> vi slaves</h4>\n<pre><code>master\nslave1\nslave2\n</code></pre>\n<h4 id=\"vi-yarn-sitexml\"><a class=\"anchor\" href=\"#vi-yarn-sitexml\">#</a> vi yarn-site.xml</h4>\n<pre><code>&lt;configuration&gt;\n&lt;!-- Site specific YARN configuration properties --&gt;\n&lt;!-- reducer获取数据的方式 --&gt;\n&lt;property&gt;\n &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;\n &lt;value&gt;mapreduce_shuffle&lt;/value&gt;\n&lt;/property&gt;\n&lt;!-- 指定YARN的ResourceManager的地址 --&gt;\n&lt;property&gt;\n&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;\n&lt;value&gt;master&lt;/value&gt;\n &lt;/property&gt;\n &lt;!-- 关闭虚拟内存的检测 --&gt;\n &lt;property&gt;  \n    &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;\n    &lt;value&gt;false&lt;/value&gt;\n&lt;/property&gt; \n&lt;/configuration&gt;\n</code></pre>\n<h4 id=\"vi-yarn-envsh\"><a class=\"anchor\" href=\"#vi-yarn-envsh\">#</a> vi <span class=\"exturl\" data-url=\"aHR0cDovL3lhcm4tZW52LnNo\">yarn-env.sh</span></h4>\n<pre><code>export JAVA_HOME=/opt/module/jdk1.8\n</code></pre>\n<h4 id=\"vi-hadoop-envsh\"><a class=\"anchor\" href=\"#vi-hadoop-envsh\">#</a> vi <span class=\"exturl\" data-url=\"aHR0cDovL2hhZG9vcC1lbnYuc2g=\">hadoop-env.sh</span></h4>\n<pre><code>export JAVA_HOME=/opt/module/jdk1.8\n</code></pre>\n<h4 id=\"vi-mapred-sitexml\"><a class=\"anchor\" href=\"#vi-mapred-sitexml\">#</a> vi mapred-site.xml</h4>\n<pre><code>先改名，因为本身是没有mapred-site.xml这个文件的\n\nmv mapred-site.xml.template mapred-site.xml\n</code></pre>\n<pre><code>&lt;configuration&gt;\n&lt;!-- 指定mr运行在yarn上 --&gt;\n &lt;property&gt;\n\t&lt;name&gt;mapreduce.framework.name&lt;/name&gt;\n\t&lt;value&gt;yarn&lt;/value&gt;\n &lt;/property&gt;\n &lt;property&gt;\n\t&lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;\n\t&lt;value&gt;master:10020&lt;/value&gt;\n &lt;/property&gt;\n &lt;property&gt;\n\t&lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;\n\t&lt;value&gt;master:19888&lt;/value&gt;\n &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre>\n<h3 id=\"8-把master下修改的文件分发到slave1和slave2下\"><a class=\"anchor\" href=\"#8-把master下修改的文件分发到slave1和slave2下\">#</a> 8、把 master 下修改的文件分发到 slave1 和 slave2 下</h3>\n<pre><code>scp -r /opt/module/ root@slave1:/opt\n\nscp -r /opt/module/ root@slave2:/opt\n\nscp -r /etc/profile root@slave1:/etc/profile\n\nscp -r /etc/profile root@slave2:/etc/profile\n</code></pre>\n<pre><code>source /etc/profile\t#分别在两个分节点上\n</code></pre>\n<h3 id=\"9-测试集群\"><a class=\"anchor\" href=\"#9-测试集群\">#</a> 9、测试集群</h3>\n<pre><code>hdfs namenode -format\t先格式化（只在主节点上）\n</code></pre>\n<h5 id=\"启动\"><a class=\"anchor\" href=\"#启动\">#</a> 启动</h5>\n<pre><code>start-all.sh\t#只在主节点上\n</code></pre>\n<pre><code>jps\n</code></pre>\n<h5 id=\"打开浏览器-httpmaster50070\"><a class=\"anchor\" href=\"#打开浏览器-httpmaster50070\">#</a> 打开浏览器 <span class=\"exturl\" data-url=\"aHR0cDovL21hc3Rlcjo1MDA3MC8=\">http://master:50070/</span></h5>\n",
            "tags": [
                "Hadoop搭建",
                "搭建"
            ]
        },
        {
            "id": "https://www.jackfruit.top/2023/02/27/hadoop-HA%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/",
            "url": "https://www.jackfruit.top/2023/02/27/hadoop-HA%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/",
            "title": "hadoop HA安装配置",
            "date_published": "2023-02-27T03:30:26.000Z",
            "content_html": "<h1 id=\"hadoop-ha安装配置\"><a class=\"anchor\" href=\"#hadoop-ha安装配置\">#</a> Hadoop HA 安装配置</h1>\n<h2 id=\"hdfs-sitexml\"><a class=\"anchor\" href=\"#hdfs-sitexml\">#</a> hdfs-site.xml</h2>\n<p>Hadoop 守护进程的配置项</p>\n<pre><code>&lt;configuration&gt;\n        &lt;property&gt;\n                &lt;name&gt; dfs.replication &lt;/name&gt;\n                &lt;value&gt;3&lt;/value&gt;\n        &lt;/property&gt;\n        &lt;property&gt;\n                &lt;name&gt;dfs.nameservices&lt;/name&gt;\n                &lt;value&gt;mycluster&lt;/value&gt;\n        &lt;/property&gt;\n&lt;!-- 集群中NameNode节点都有哪些 --&gt;\n        &lt;property&gt;\n                &lt;name&gt;dfs.ha.namenodes.mycluster&lt;/name&gt;\n                &lt;value&gt;nn1,nn2&lt;/value&gt;\n        &lt;/property&gt;\n\n        &lt;!-- nn1的RPC通信地址 --&gt;\n        &lt;property&gt;\n                &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn1&lt;/name&gt;\n                &lt;value&gt;master:8020&lt;/value&gt;\n        &lt;/property&gt;\n\n        &lt;!-- nn2的RPC通信地址 --&gt;\n        &lt;property&gt;\n                &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn2&lt;/name&gt;\n                &lt;value&gt;slave1:8020&lt;/value&gt;\n        &lt;/property&gt;\n\n        &lt;!-- nn1的http通信地址 --&gt;\n        &lt;property&gt;\n                &lt;name&gt;dfs.namenode.http-address.mycluster.nn1&lt;/name&gt;\n                &lt;value&gt;master:50070&lt;/value&gt;\n        &lt;/property&gt;\n\n        &lt;!-- nn2的http通信地址 --&gt;\n        &lt;property&gt;\n                &lt;name&gt;dfs.namenode.http-address.mycluster.nn2&lt;/name&gt;\n                &lt;value&gt;slave1:50070&lt;/value&gt;\n        &lt;/property&gt;\n &lt;!-- 指定NameNode元数据在JournalNode上的存放位置 --&gt;\n        &lt;property&gt;\n                &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;\n                &lt;value&gt;qjournal://master:8485;slave1:8485;slave2:8485/mycluster&lt;/value&gt;\n        &lt;/property&gt;\n\n        &lt;!-- 配置隔离机制，即同一时刻只能有一台服务器对外响应 --&gt;\n      \n        &lt;property&gt;\n                &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;\n                &lt;value&gt;shell(/bin/true)&lt;/value&gt;\n        &lt;/property&gt;\n\n\n        &lt;!-- 使用隔离机制时需要ssh无秘钥登录--&gt;\n        &lt;property&gt;\n                &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;\n                &lt;value&gt;/root/.ssh/id_rsa&lt;/value&gt;\n        &lt;/property&gt;\n\n        &lt;!-- 声明journalnode服务器存储目录--&gt;\n        &lt;property&gt;\n                &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;\n                &lt;value&gt;/opt/modules/hadoop-2.6.0/data/jn&lt;/value&gt; \n        &lt;/property&gt;\n\n        &lt;!-- 关闭权限检查--&gt;\n        &lt;property&gt;\n                &lt;name&gt;dfs.permissions.enable&lt;/name&gt;\n                &lt;value&gt;false&lt;/value&gt;\n        &lt;/property&gt;\n\n        &lt;!-- 访问代理类：client，mycluster，active配置失败自动切换实现方式--&gt;\n        &lt;property&gt;\n                &lt;name&gt;dfs.client.failover.proxy.provider.mycluster&lt;/name&gt;\n                &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;\n        &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre>\n<h2 id=\"core-sitexml\"><a class=\"anchor\" href=\"#core-sitexml\">#</a> core-site.xml</h2>\n<p>Hadoop Core 的配置项</p>\n<pre><code>&lt;configuration&gt;\n &lt;property&gt;\n                &lt;name&gt;fs.defaultFS&lt;/name&gt;\n                &lt;value&gt;hdfs://mycluster&lt;/value&gt;\n        &lt;/property&gt;\n\n        &lt;property&gt;\n                &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;\n                &lt;value&gt;/opt/module/hadoop-2.7.7/data&lt;/value&gt;\n        &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre>\n<h2 id=\"hadoop-envsh\"><a class=\"anchor\" href=\"#hadoop-envsh\">#</a> <span class=\"exturl\" data-url=\"aHR0cDovL2hhZG9vcC1lbnYuc2g=\">hadoop-env.sh</span></h2>\n<p>配置 java 路径，同时也记录了脚本中要用到的环境变量，以运行 hadoop</p>\n<pre><code>export JAVA_HOME=/opt/module/jdk1.8\n</code></pre>\n<h2 id=\"slaves\"><a class=\"anchor\" href=\"#slaves\">#</a> slaves</h2>\n<p>记录的是集群里所有 DataNode 的主机名</p>\n<pre><code>master\nslave1\nslave2\n</code></pre>\n<h2 id=\"yanr-sitexml\"><a class=\"anchor\" href=\"#yanr-sitexml\">#</a> yanr-site.xml</h2>\n<p>主要记录了 resourcemanager 的配置文件</p>\n<pre><code>&lt;configuration&gt;\n\n&lt;!-- Site specific YARN configuration properties --&gt;\n    &lt;property&gt;\n        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;\n        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;\n    &lt;/property&gt;\n\n &lt;!--启用resourcemanager ha--&gt;\n    &lt;property&gt;\n        &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt;\n        &lt;value&gt;true&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!--声明两台resourcemanager的地址--&gt;\n    &lt;property&gt;\n        &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt;\n        &lt;value&gt;cluster-yarn1&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;property&gt;\n        &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt;\n        &lt;value&gt;rm1,rm2&lt;/value&gt;\n    &lt;/property&gt;\n\n\t&lt;property&gt;\n        &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt;\n        &lt;value&gt;slave1&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;property&gt;\n        &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt;\n        &lt;value&gt;slave2&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!--指定zookeeper集群的地址--&gt;\n    &lt;property&gt;\n        &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt;\n        &lt;value&gt;master:2181,slave1:2181,slave2:2181&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!--启用自动恢复--&gt;\n    &lt;property&gt;\n        &lt;name&gt;yarn.resourcemanager.recovery.enabled&lt;/name&gt;\n        &lt;value&gt;true&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!--指定resourcemanager的状态信息存储在zookeeper集群--&gt;\n    &lt;property&gt;\n     &lt;name&gt;yarn.resourcemanager.store.class&lt;/name&gt;\n     &lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore&lt;/value&gt;\n    &lt;/property&gt;\n    \n&lt;/configuration&gt;\n</code></pre>\n<h2 id=\"mapred-sitexml\"><a class=\"anchor\" href=\"#mapred-sitexml\">#</a> mapred-site.xml</h2>\n<p>MapReduce 守护进程的配置项</p>\n<pre><code>&lt;!--指定运行mapreduce的环境是yarn--&gt;\n&lt;property&gt;\n  &lt;name&gt;mapreduce.framework.name&lt;/name&gt;\n  &lt;value&gt;yarn&lt;/value&gt;\n&lt;/property&gt;\n</code></pre>\n",
            "tags": [
                "Hadoop搭建",
                "搭建"
            ]
        },
        {
            "id": "https://www.jackfruit.top/2023/02/27/flume%E5%AE%89%E8%A3%85%EF%BC%88%E5%8C%85%E5%90%ABhdfs%E6%93%8D%E4%BD%9C%EF%BC%89/",
            "url": "https://www.jackfruit.top/2023/02/27/flume%E5%AE%89%E8%A3%85%EF%BC%88%E5%8C%85%E5%90%ABhdfs%E6%93%8D%E4%BD%9C%EF%BC%89/",
            "title": "flume安装（包含hdfs操作）",
            "date_published": "2023-02-27T03:29:22.000Z",
            "content_html": "<h1 id=\"flume-安装\"><a class=\"anchor\" href=\"#flume-安装\">#</a> flume 安装</h1>\n<h3 id=\"1-解压\"><a class=\"anchor\" href=\"#1-解压\">#</a> 1、解压</h3>\n<pre><code>tar -zxvf /opt/software/apache-flume-1.7.0-bin.tar.gz -C /opt/module\n</code></pre>\n<h3 id=\"二-配置-flume-envsh\"><a class=\"anchor\" href=\"#二-配置-flume-envsh\">#</a> 二、配置 <span class=\"exturl\" data-url=\"aHR0cDovL2ZsdW1lLWVudi5zaA==\">flume-env.sh</span></h3>\n<pre><code>cd /opt/module/apache-flume-1.7.0-bin/conf\n</code></pre>\n<pre><code>mv flume-env.sh.template flume-env.sh\n</code></pre>\n<p><strong>vi <span class=\"exturl\" data-url=\"aHR0cDovL2ZsdW1lLWVudi5zaA==\">flume-env.sh</span></strong></p>\n<pre><code>export JAVA_HOME=/opt/module/jdk1.8.0_212\n</code></pre>\n<h3 id=\"三-配置环境变量\"><a class=\"anchor\" href=\"#三-配置环境变量\">#</a> 三、配置环境变量</h3>\n<p><strong>vi /etc/profile</strong></p>\n<pre><code>#set flume\nexport FLUME_HOME=/opt/module/apache-flume-1.7.0-bin\nexport FLUME_CONF_DIR=$FLUME_HOME/conf\nexport PATH=$PATH:$FLUME_HOME/bin\n</code></pre>\n<pre><code>source /etc/profile\t\t#生效环境变量\n</code></pre>\n<h3 id=\"四-查看flume版本\"><a class=\"anchor\" href=\"#四-查看flume版本\">#</a> 四、查看 flume 版本</h3>\n<pre><code>flume-ng version\n</code></pre>\n<h3 id=\"五-配置文件\"><a class=\"anchor\" href=\"#五-配置文件\">#</a> 五、配置文件</h3>\n<p><strong>1. 将 hadoop 的 hdfs-site.xml 和 core-site.xml 放到 flume/conf 下</strong></p>\n<pre><code>cp $HADOOP_HOM/etc/hadoop/core-site.xml $FLUME_HOME/conf/\ncp $HADOOP_HOM/etc/hadoop/hdfs-site.xml $FLUME_HOME/conf/\n</code></pre>\n<p><strong>2. 将 hadoop 的 jar 包拷贝到 flume 的 lib 目录下</strong></p>\n<pre><code>cp $HADOOP_HOME/share/hadoop/common/hadoop-common-2.7.7.jar  $FLUME_HOME/lib/\ncp $HADOOP_HOME/share/hadoop/common/lib/hadoop-auth-2.7.7.jar   $FLUME_HOME/lib/\ncp $HADOOP_HOME/share/hadoop/common/lib/commons-configuration-1.6.jar   $FLUME_HOME/lib/\n</code></pre>\n<p><strong>3. 配置 flume2.conf</strong></p>\n<p>创建监控文件夹</p>\n<pre><code>mkdir /logs\n</code></pre>\n<p>在 flume 安装目录下的 conf 下创建一个 flume2.conf 文件，并写入配置</p>\n<pre><code>#定义agent名， source、channel、sink的名称\na1.sources = r1\na1.channels = c1\na1.sinks = k1\n\n#具体定义source\na1.sources.r1.type = spooldir\n#先创建此目录，保证里面空的\na1.sources.r1.spoolDir = /logs\n\n#具体定义sink\na1.sinks.k1.type = hdfs\n\n#集群的nameservers名字     \na1.sinks.k1.hdfs.path = hdfs://master:9000/tmp/flume\n\na1.channels.c1.type=file\n\n#组装source、channel、sink\na1.sources.r1.channels = c1\na1.sinks.k1.channel = c1\n</code></pre>\n<p><strong>4. 启动 flume (保证首先启动 hdfs)</strong></p>\n<p>在 /opt/module/flume-1.7.0 目录下</p>\n<pre><code>bin/flume-ng agent -n a1 -f conf/flume2.conf\n</code></pre>\n<p><strong>5. 测试</strong></p>\n<p>重新打开一个窗口</p>\n<pre><code>cp /opt/module/hadoop-2.7.7/logs/hadoop-root-datanode-master.log /logs\n</code></pre>\n<p><strong>6. 查看</strong></p>\n<pre><code>hadoop fs -cat /tmp/flume/XXXXXXXXX\n</code></pre>\n<p>备注：</p>\n<p>Hadoop 文件修改方式</p>\n<pre><code>rm 删除目录或者文件\n\n使用方法:hadoop fs -rm [文件路径]  删除文件夹加上 -r\n示例: hadoop fs -rm /test1.txt\n</code></pre>\n<pre><code>cat 查看文件内容\n\n使用方法：hadoop fs -cat URI [URI …]\n示例： hadoop fs -cat /in/test2.txt\n</code></pre>\n<pre><code>ls 显示目录下的所有文件或者文件夹\n\n使用方法： hadoop fs -ls [uri形式目录]\n示例: hadoop fs –ls /    显示根目录下的所有文件和目录\n\n显示目录下的所有文件可以加 -R 选项\n示例: hadoop fs -ls -R /\n</code></pre>\n<pre><code>copyFromLocal 复制本地文件到hdfs\n\n使用方法：hadoop fs-copyFromLocal &lt;localsrc&gt; URI\n除了限定源路径是一个本地文件外，和put命令相似\n</code></pre>\n<pre><code>get 复制文件到本地系统\n\n使用方法：hadoop fs -get[-ignorecrc] [-crc] &lt;src&gt; &lt;localdst&gt; \n复制文件到本地文件系统。可用-ignorecrc选项复制CRC校验失败的文件。使用-crc选项复制文件以及CRC信息。\n示例：hadoop fs -get/word /usr/wisedu/temp/word.txt\n</code></pre>\n<pre><code>copyToLocal 复制 文件到本地系统\n\n使用方法：hadoop fs-copyToLocal [-ignorecrc] [-crc] URI &lt;localdst&gt;\n除了限定目标路径是一个本地文件外，和get命令类似。\n示例：hadoop fs - copyToLocal/word /usr/wisedu/temp/word.txt\n</code></pre>\n<pre><code>put 复制文件。将文件复制到hdfs系统中，也可以是从标准输入中读取文件，此时的dst是一个文件\n\n使用方法: hadoop fs -put &lt;localsrc&gt; ... &lt;dst&gt;\n示例：Hadoop fs -put /usr/wisedu/temp/test1.txt /\n从标准输入中读取文件：hadoop fs -put -/in/myword\n</code></pre>\n<pre><code>cp 复制系统内文件\n \n使用方法：hadoopfs -cp URI [URI …] &lt;dest&gt;\n将文件从源路径复制到目标路径。这个命令允许有多个源路径，此时目标路径必须是一个目录。 \n示例：hadoop fs -cp /in/myword/word\n</code></pre>\n<pre><code>mv 将文件从源路径移动到目标路径。这个命令允许有多个源路径，此时目标路径必须是一个目录。不允许在不同的文件系统间移动文件。\n\n使用方法：hadoop fs -mv URI [URI …] &lt;dest&gt;\n示例：hadoop fs -mv /in/test2.txt /test2.txt\n</code></pre>\n<pre><code>du 显示文件大小。显示目录中所有文件的大小。\n\n使用方法：hadoop fs -du URI [URI …]\n示例: hadoop fs -du /\n\n显示当前目录或者文件夹的大小可加选项 -s\n示例: hadoop fs -du -s /\n</code></pre>\n",
            "tags": [
                "Hadoop搭建",
                "搭建"
            ]
        },
        {
            "id": "https://www.jackfruit.top/2023/02/27/flink%E5%AE%89%E8%A3%85/",
            "url": "https://www.jackfruit.top/2023/02/27/flink%E5%AE%89%E8%A3%85/",
            "title": "flink安装",
            "date_published": "2023-02-27T03:27:53.000Z",
            "content_html": "<h1 id=\"flink安装\"><a class=\"anchor\" href=\"#flink安装\">#</a> flink 安装</h1>\n<h3 id=\"解压\"><a class=\"anchor\" href=\"#解压\">#</a> 解压</h3>\n<pre><code>tar -zxvf /opt/software/flink-1.10.2-bin-scala_2.11.tgz -C /opt/module\n\ncd /opt/module/flink-1.10.2\n</code></pre>\n<h3 id=\"修改配置文件\"><a class=\"anchor\" href=\"#修改配置文件\">#</a> 修改配置文件</h3>\n<p><strong>vi conf/flink-conf.yaml</strong></p>\n<pre><code>jobmanager.rpc.address: master\n</code></pre>\n<p><strong>vi conf/slaves</strong></p>\n<pre><code>slave1\nslave2\n</code></pre>\n<p><strong>vi conf/masters</strong></p>\n<pre><code>master\n</code></pre>\n<h3 id=\"同步节点\"><a class=\"anchor\" href=\"#同步节点\">#</a> 同步节点</h3>\n<pre><code>scp -r /opt/module/flink-1.10.2 root@slave1:/opt/module\nscp -r /opt/module/flink-1.10.2 root@slave2:/opt/module\nscp -r /etc/profile root@slave1:/etc/profile\t#将环境变量profile文件分发到slave1节点\nscp -r /etc/profile root@slave2:/etc/profile\t#将环境变量profile文件分发到slave2节点\n</code></pre>\n<h3 id=\"启动集群\"><a class=\"anchor\" href=\"#启动集群\">#</a> 启动集群</h3>\n<pre><code>start-cluster.sh\n</code></pre>\n<pre><code>http://master:8081   访问web界面\n</code></pre>\n<h3 id=\"问题\"><a class=\"anchor\" href=\"#问题\">#</a> 问题</h3>\n<pre><code>export HADOOP_CLASSPATH=`hadoop classpath`\n\nhadoop classpath\n\n再启动\n\nstop-cluster.sh\t#停止集群\n</code></pre>\n",
            "tags": [
                "Hadoop搭建",
                "搭建"
            ]
        },
        {
            "id": "https://www.jackfruit.top/2023/02/27/%E7%AC%AC%E4%B8%80%E6%AC%A1%E6%90%AD%E5%8D%9A%E5%AE%A2%E7%9A%84%E5%BF%83%E5%BE%97/",
            "url": "https://www.jackfruit.top/2023/02/27/%E7%AC%AC%E4%B8%80%E6%AC%A1%E6%90%AD%E5%8D%9A%E5%AE%A2%E7%9A%84%E5%BF%83%E5%BE%97/",
            "title": "学习Hadoop",
            "date_published": "2023-02-27T02:52:12.000Z",
            "content_html": "<h3 id=\"第一次编写个人博客づ-̄3-̄づ️~\"><a class=\"anchor\" href=\"#第一次编写个人博客づ-̄3-̄づ️~\">#</a> 第一次编写个人博客（づ￣3￣）づ╭❤️～</h3>\n<h5 id=\"收获\"><a class=\"anchor\" href=\"#收获\">#</a> 收获😊：</h5>\n<pre><code>\t第一次编写博客是套用别人的方法使用的，外观、图片、CSS样式、渲染器等等等....\n</code></pre>\n<p>​\t<strong>收获到许多，了解到一个网站是如何建成的（虽然是最简单搭建，用时：5 个小时多一点～～～）。比如说如何建仓库，无后端评论区，搜索引擎等，，，这些都是委托在第三方平台上搭建起来的，代码没改太多（都是 copy 别人的样式，主题，，）。现在先模仿，后期再慢慢摸索。</strong></p>\n<p>这个网站我也会维护下去，但是至于是啥时候更新就不一定了。</p>\n",
            "tags": []
        },
        {
            "id": "https://www.jackfruit.top/2023/02/26/hello-world/",
            "url": "https://www.jackfruit.top/2023/02/26/hello-world/",
            "title": "Hello World",
            "date_published": "2023-02-26T09:52:10.565Z",
            "content_html": "<p>Welcome to <span class=\"exturl\" data-url=\"aHR0cHM6Ly9oZXhvLmlvLw==\">Hexo</span>! This is your very first post. Check <span class=\"exturl\" data-url=\"aHR0cHM6Ly9oZXhvLmlvL2RvY3Mv\">documentation</span> for more info. If you get any problems when using Hexo, you can find the answer in <span class=\"exturl\" data-url=\"aHR0cHM6Ly9oZXhvLmlvL2RvY3MvdHJvdWJsZXNob290aW5nLmh0bWw=\">troubleshooting</span> or you can ask me on <span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL2hleG9qcy9oZXhvL2lzc3Vlcw==\">GitHub</span>.</p>\n<h2 id=\"quick-start\"><a class=\"anchor\" href=\"#quick-start\">#</a> Quick Start</h2>\n<h3 id=\"create-a-new-post\"><a class=\"anchor\" href=\"#create-a-new-post\">#</a> Create a new post</h3>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"><span>h</span></figcaption><table><tr><td data-num=\"1\"></td><td><pre>$ hexo new <span class=\"token string\">\"My New Post\"</span></pre></td></tr></table></figure><p>More info: <span class=\"exturl\" data-url=\"aHR0cHM6Ly9oZXhvLmlvL2RvY3Mvd3JpdGluZy5odG1s\">Writing</span></p>\n<h3 id=\"run-server\"><a class=\"anchor\" href=\"#run-server\">#</a> Run server</h3>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"><span>h</span></figcaption><table><tr><td data-num=\"1\"></td><td><pre>$ hexo server</pre></td></tr></table></figure><p>More info: <span class=\"exturl\" data-url=\"aHR0cHM6Ly9oZXhvLmlvL2RvY3Mvc2VydmVyLmh0bWw=\">Server</span></p>\n<h3 id=\"generate-static-files\"><a class=\"anchor\" href=\"#generate-static-files\">#</a> Generate static files</h3>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"><span>h</span></figcaption><table><tr><td data-num=\"1\"></td><td><pre>$ hexo generate</pre></td></tr></table></figure><p>More info: <span class=\"exturl\" data-url=\"aHR0cHM6Ly9oZXhvLmlvL2RvY3MvZ2VuZXJhdGluZy5odG1s\">Generating</span></p>\n<h3 id=\"deploy-to-remote-sites\"><a class=\"anchor\" href=\"#deploy-to-remote-sites\">#</a> Deploy to remote sites</h3>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"><span>h</span></figcaption><table><tr><td data-num=\"1\"></td><td><pre>$ hexo deploy</pre></td></tr></table></figure><p>More info: <span class=\"exturl\" data-url=\"aHR0cHM6Ly9oZXhvLmlvL2RvY3Mvb25lLWNvbW1hbmQtZGVwbG95bWVudC5odG1s\">Deployment</span></p>\n",
            "tags": []
        }
    ]
}